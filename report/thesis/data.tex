The LISS panel \cite{scherpenzeel2010liss} started in 2007 in the Netherlands. It takes the form of an online questionnaire
which is held yearly, on various topics such as health, religion, leisure, family, work and so on.
Its data is freely available for the purposes of research and policymaking.
Besides these studies, background variables are collected on a monthly basis, like age, household composition,
income and primary occupation.
Recruitment is done invite-only to limit self-selection, although it cannot be wholly prevented as
participation is still voluntary and motivated by a financial incentive. Additionally, some self-selection might occur
in the roughly 80\% response rate, despite efforts to contact inactive panel members. Due to a yearly attrition of 12\%,
refreshment samples were occasionally introduced, selected such as to balance representativeness of household type,
age and ethnicity \cite{lissdata_methodology}. This also effectively introduces missing data.
The nature and impact of this missing data is further discussed in \Cref{sec:data:missingness}.

The focus of this study is on two of the core studies, namely the Social Integration and Leisure study and the Health study.
The prior directly measures engagement in physical exercise by question 104, ``Do you practice sports?''. This question
has been included since 2012.
Mental health is queried in the latter, though not as directly. Questions 11 through 15 are the five-item Mental Health Inventory
(MHI5), a standard screening questionnaire for mental health \cite{berwick1991performance}. These questions have been included
since 2008.
Respondents are asked how often, over the past four weeks,
they felt very anxious; so down that nothing could cheer them up; calm and peaceful; depressed and gloomy; and happy.
Responses are measured on a 6-point Likert scale ranging from ``never'' to ``continuously'', and the scores are combined
linearly to create the MHI5 score from 0 to 100 with increments of 4, where a higher score indicates superior mental health.
Refer to \Cref{chap:app:liss_questions} for a description of all of the variables studied,
including the controls and mediators that are selected in \Cref{sec:modelling:regressors}.

\section{Quality Issues}
\label{sec:data:quality}
Beyond the problem of self-selection as already discussed, there are more issues that plague the studied data.
Naturally, all the information is self-reported. This can lead to noise in the data, as for instance the difference
between ``sometimes'' and ``often'' in the MHI5 screening can be subjective. Furthermore, \citeA{brown2018mental} find that
mental health is typically overreported, leading to a bias towards zero when estimating the effect of an intervention.
Self-reporting bias in general is a well-established phenomenon \cite{rosenman2011measuring}, but in practice it is a
necessary price to pay when gathering data at such a large scale. The large sample size of the LISS panel might
help to preserve statistical power in the face of the increased variance, but the resulting bias cannot be overcome
without explicitly modelling the bias-inducing effect, which is a psychological phenomenon that is beyond the scope of this study.

Another risk factor for poor data quality is the extensiveness of the questionnaire. The total yearly LISS study
comprises multiple thousands of questions, and it is likely that this causes respondents to not answer each question
with as much care as they would on a shorter questionnaire, and perhaps even more significantly, it might lead to
failure to respond in the first place.
To combat this, the core studies are held at different times of year. The Health study is (almost) always held in November
through December, whereas the Leisure study was held in February through March before 2015, and October through November since.
The effect of questionnaire length has been studied in the literature, with somewhat conflicting results. \citeA{galesic2009effects} for instance
find worse response quality for questions later in the survey as compared to earlier. On the other hand, \citeA{andreadis2020impact,subar2001shorter}
do not find significant evidence for improved response rate and data quality with shorter questionnaires. The latter
also note ease of administration may compensate for length, in which regard the online nature and typically multiple-choice
questions of the panel do well. The impact of the length of the panel is thus likely not a major concern.

The fact that the Leisure and Health study aren't held at the same time of year means it has to be chosen whether
a wave of the panel is considered to be a Health study with the most recent Leisure study, or with the first upcoming
Leisure study.
Sports has only been included in the panel since 2012, whereas the MHI5 score has been recorded since earlier.
Noting this, the choice is made to consider a Health study with the previous Leisure study as one wave,
so as to have as many available waves as possible.
This effectively introduces the assumption that exercise status in March is a good predictor of exercise status
in November of the same year, and in so far as it is not ($R^2 < 1$),
noise is introduced into the data, reducing the power of the study.
Since the background variables are recorded on a monthly basis, they are chosen to align with the Health study,
namely November each year.

A curious general finding is that the correlation between MHI5 score and sports is very low in the data,
between $\rho = 0.042$ and $\rho = 0.095$, even before controlling for covariates.
This is very different from for instance \citeA{endrawan2023relationship} who find $\rho = 0.893$ between
physical activity and mental health.
Such a small correlation leaves very little statistical power to find a causal effect, and may be a result of
the very general phrasing of the question for sports which may cause noisy data, but even considering that effect
the correlation coefficient is strikingly small.

A worthwhile consideration is the impact of the Covid-19 pandemic on the data. The negative effect of the pandemic on public
mental health has been the topic of much discussion \cite{cullen2020mental,kumar2021covid} and has been empirically verified \cite{kupcova2023effects}.
Additionally, due to closing of public facilities, people engaged in exercise significantly less \cite{amini2021covid}.
The pandemic thus seems a priori to be a significant risk factor for endogeneity in the present analysis.
However, curiously, neither the effect of the pandemic on mental health nor its effect on rates of physical exercise
seem to be present in the data. As \Cref{fig:data:sample_moments_y_x} shows, sample statistics of both variables
vary little over time with no appreciably change after the onset of the Covid pandemic in 2020.
This puts the validity of the data into question, as these findings conflict with the literature on this topic.
The constance in sports engagement may be explained by the fact that while sports facilities closed, people had more spare time
as for instance social events and commuting were no longer possible, which appears to compensate for the effect of
closing sports facilities.
However, the lack of decrease in mental health is quite remarkable. It is perhaps an artefact of biases introduced
due to self-reported data, as people may have measured their state relative that of people around them, rather than
relative to themselves previously.
Regardless, based on the lack of impact on the sample statistics, the Covid pandemic will not be of further consideration
for this work.

\begin{figure}[htbp]
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includesvg[width=\textwidth]{figures/data/boxplot_mhi5.svg}
        \vspace{0.1em}
        \subcaption{Boxplot of the MHI5 score for each available year. Whiskers are 10th and 90th percentiles.
        Note the appreciable varability in the median is simply because the MHI5 score has an interval of 4}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includesvg[width=\textwidth]{figures/data/errorbar_sports.svg}
        \vspace{0.1em}
        \subcaption{Rate of engagement in exercise for each available year}
    \end{subfigure}
    \caption{Distributions of the MHI5 score and sports engagement across years}
    \label{fig:data:sample_moments_y_x}
\end{figure}

\section{Preprocessing}
\label{sec:data:preprocessing}
\subsubsection{MHI5}
As said, the MHI5 score is derived linearly from the responses to the five relevant questions. It was found that
there is no partial missingness, in the sense that either all five questions were answered or none of them were answered.
The score is then simply calculated when all responses are given, and missing otherwise.
Listwise deletion is performed for those individuals for whom the MHI5 score is always missing, as they provide no
information towards the relationship being studied.

\subsubsection{Sports}
The variable is used as-is, but as with MHI5, those individuals for whom sports is always missing are deleted from the data.
A consideration is to also remove individuals for whom sports is constant in time, i.e. either always ``no'' or always ``yes'',
as for such individuals there is no within-person variability to be studied. Such subjects are likely to be subject
to unmeasured individual-specific confounders, causing endogeneity.
However, upon further consideration this appears to imply a rather arbitrary threshold. For example, if one individual has a
probability of 1 to engage in exercise yet another has a probability of 0.9, it is not unlikely that during their
panel participation, both always engaged in exercise, yet these are clearly different individuals.
A threshold of 90\% engagement in sports may then be used, but this choice quickly becomes arbitrary.
Additionally, opposed to endogeneity caused by unmeasured confounders is endogeneity caused by the selection bias
that would occur if such individuals were left out.
The choice is thus made to include such observations.

\subsubsection{Dummy Encoding}
Many questions in the study are measured on a categorical or ordinal scale (f.i. a Likert scale), which cannot be
meaningfully included directly as regressors, for example primary occupation, ethnicity and education level.
Naturally, such variables are expanded to dummy variables, with one dummy variable for each level of the original variable
(also known as one-hot encoding).

Additionally, even for variables that are measured on an ordinal scale, for instance age, income and bmi, the effePt on mental wellbeing is very unlikely to
be linear. Without expert knowledge on the exact relationship between each variable
and mental health and in order to avoid model complexity, these variables are stratified into categories and then also
included as dummy variables. While this involves some loss of information, it also simultaneously provides robustness
against outliers, such as individuals whose reported height and weight imply an infeasible body mass index (BMI) of over 100.
Refer to \Cref{tab:data:stratification} for the exact stratification.
For age, the stratification is chosen as to align roughly with different phases of life, as the strata roughly represent
children, students, young adults, middle adults and retirees.
For income, the strata represent no income, minimal income, regular income and high income.
For BMI, the strata reflect underweight, normal weight, overweight and obese, as derived from \citeA{who_healthy_lifestyle_2010}.
Additionally, for BMI, individuals who reported a weight or height that was excessively high or low were assigned NA as their BMI.
Lower cutoffs were 5\,cm and 1\,kg and upper cutoffs were 270\,cm (the height of the tallest man ever) and 635\,kg
(the weight of the heaviest man ever). These are conservative bounds so as to eliminate outliers due to for instance
mistyping, but with minimal subjective judgment to avoid researches biases.
While technically, this introduces MNAR missingness with respect to BMI, even though only about 0.14\% of the observations are
assigned to be NA by this, these extreme outliers are likely due to mistyping and are thus only weakly related to the
true values, which means the impact of the MNAR data should be very minimal.

\begin{table}[htbp]
    \centering
    \caption{Stratification applied to variables whose effect is unlikely to be linear. All bounds are left-inclusive}
    \label{tab:data:stratification}
    \begin{tabular}{l|c|c}
        Variable & Stratum Bounds & Number of Strata \\
        \hline
        % This hfill abomination makes stuff nicely spread out throughout the table
        % Just write it with regular dashes and then hit em with an
        % s/ - / \hfill- \hfill/g
        Age        & 0 \hfill- \hfill18 \hfill- \hfill25 \hfill- \hfill40 \hfill- \hfill67 \hfill- \hfill$ \infty$ & 5  \\
        Income (€) & 0 \hfill- \hfill1 \hfill- \hfill15000 \hfill- \hfill50000 \hfill- \hfill$ \infty$ & 4  \\
        BMI        & 0 \hfill- \hfill18.5 \hfill- \hfill25.0 \hfill- \hfill30 \hfill- \hfill$ \infty$  & 4  \\
    \end{tabular}
\end{table}

If such a dummy-encoded variable was missing, that observation is assigned NA for each dummy level, and this missing
data will then be naturally handled by the method explained in \Cref{sec:methods:fiml}.
An alternative would be to assign 0 to each dummy level. However, that would imply that on average, mental wellbeing of non-respondents
is equal to the mental wellbeing in the dummy level that is left out for identification, which is an assumption that
clearly need not hold in general.

\subsubsection{Employment status}
Employment status is the only covariate for which noteworthy preprocessing is done.
Namely, it is derived from a multiple-choice question on primary occupation with 14 different possible answers,
which would entail a lot of dummy variables.
For the sake of parsimony, these answers are grouped into Employed, Unemployed, Student, Homemaker, Retired and
Unable to work. This captures the most major forms of employment, while losing the nuance of for instance
the difference between general employment versus employment in a family business or voluntary work, a nuance which
is assumed to be of lesser relevance.

\section{Missingness}
\label{sec:data:missingness}
After removing individuals for which MHI5 or sports are always unavailable, we are left with data for 12\,920 individuals
for the years 2008 through 2023.
However, a significant portion of all data is missing. For some variables in specific years, all data is available,
but for others upwards of 70\% is missing. Across all variables considered in this study, after preprocessing,
the average percentage of missing variables is 48.8\%.
This missing data is due to multiple factors. Firstly, due to attrition or due to joining the panel
in one of the later recruitment waves, data for a certain individual might not be available for all waves.
Additionally, the Leisure study only started in 2008, so no data from it is available for 2007.
In 2014, the decision was made to postpone the Health study until May 2015, as a result of which the study was not held
that year, leaving a gap in the data. From 2016 onwards, the study was held in November again \cite{marchand2025personal}.
In addition to the missing information in 2014, the different time of year may cause anomalies in the data for that year,
which is something to be considered.
Lastly, an individual may give a partial response, either in the form of not answering some of the questions in a study,
or in the form of not responding to an entire study for a year (even if they did respond to other studies).

A noteworthy quantity is the coverage between sports and the MHI5 score, defined as the percentage of observations
(for each year) for which both sports and the MHI5 score is available.
This can be found in \Cref{tab:data:coverage}. It is still somewhat low even after removing individuals for whom MHI5
or sports are always missing, around 40\% each year.
As a result, out of the almost 13\,000 individuals each year, only about 5\,000 contribute direct information
to the relationship of interest.

\begin{table}[htbp]
    \centering
    \caption{Coverage of sports and MHI5 score each year, i.e. percentage of observations for which both are available.
    This is after removing individuals for whom MHI5 or sports is always missing}
    \label{tab:data:coverage}
    \begin{tabular}{lc}
        \toprule
        Year & Coverage \\
        \hline
        2012 & 40.4\% \\
        2013 & 38.6\% \\
        2014 & -      \\
        2015 & 42.8\% \\
        2016 & 40.0\% \\
        2017 & 44.2\% \\
        2018 & 40.6\% \\
        2019 & 37.3\% \\
        2020 & 42.6\% \\
        2021 & 37.2\% \\
        2022 & 42.8\% \\
        2023 & 43.9\% \\
        \bottomrule
    \end{tabular}
\end{table}

When dealing with missing data, it is important to consider why the data is missing, as different reasons for the missingness
have differing impacts on the outcomes. In general, we differentiate between three different forms of missingness,
namely missing completely at random (MCAR), missing at random (MAR) and missing not at random (MNAR).
MCAR is the least problematic as it entails the absence of the data is utterly random and not related to any of the
variables used in the study. In this case, we simply lose statistical power due to the missing information, but
no biases are introduced.
The other extreme, MNAR, entails that whether the data is missing for some variable depends on the value of the variable itself.
Imagine for instance an online survey sent out to a chosen group of people that asks how much one uses the internet.
Clearly, there would be a selection bias, as no respondents would say ``never''.
As such, in the face of MNAR data, serious biases may be introduced into the analysis. No general solutions exist for handling
MNAR missingness. It might be possible to handle it via a case-specific model of the exact mechanism leading to missing data,
but this would at least require extensive expert knowledge of the data being studied. Note that listwise deletion,
that is simply removing observations for which some data is missing, does not prevent these biases from occurring,
as the remaining studied data is not representative of the population as a whole.
Lastly, there is MAR. MAR data is data for which the missingness depends on the values of other variables in the dataset,
but not the variable itself. In this case, general solutions exist, which preserve as much information as possible
without introducing biases.

SEM has a natural solution to MCAR or MAR data which will be explained in \Cref{sec:methods:sem}.
However, it cannot naturally deal with MNAR data, so a discussion of which mechanisms are present in the LISS data is prudent.
First, consider missingness due to late recruitment. As explained earlier, selection for late recruitment is done based
on household type, age and ethnicity, so as to make the panel representative of the general population. For cases of missing
data due to late recruitment, it is thus MAR in general, but MNAR with respect to those free background variables.
Since those variables are only used as controls in this work, the impact of the MNAR data is likely minimal.
Second, consider attrition. Centerdata has studied attrition \cite{vos2009attrition}, and it was found the only significant
predictors of attrition were age, whether internet was provided and whether there was a disabled person
in the household (Table 4 of the report). The latter two variables are not variables studied in this work, so through
the same argument as for late recruitment, attrition is only of minor concern.
The missing information for the Leisure panel in 2007 can be considered MCAR, and while it cannot be said for certain as
the reason for its absence is not known, the same the missing Health panel wave of 2014.
Lastly, there is missingness due to incomplete responses, which poses a more significant problem, as
poor mental wellbeing is known to be associated with worse self-efficacy.
\citeA{grotan2019mental} found students with mental distress were four times more likely to experience low
self-efficacy, and the association is corroborated in other literature, f.i. \citeA{schonfeld2016effects,najafi2007relationship}.
Lower self-efficacy would almost by definition decrease the probability of responding to the survey, thus providing
a significant mechanism for MNAR missingness of mental health.
To study this, I examine what percentage of MHI5 scores is missing in between each individual's first and last
available MHI5 score, which is just over 9\%. This slightly underestimates the true number, as nonresponse
in the first or last year of panel participation would not be measured. Nevertheless, it should be a reasonable
estimate. Some proportion of this will be just MCAR or MAR missingness, but it cannot be known what proportion.
Since self-efficacy is not directly measured in the panel and due to a lack of expert knowledge on this association,
the MNAR missingness is not handled explicitly in this work and thus remains as a limitation of the study.
In a more strictly controlled environment than online web surveys, such missingness might be avoided, but it is likely
a necessary price to pay when studying mental health in large samples.
